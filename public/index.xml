<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>aperture. on </title>
    <link>https://1rvinn.github.io/</link>
    <description>Recent content in aperture. on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 10 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://1rvinn.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>mitm attacks</title>
      <link>https://1rvinn.github.io/build/mitm_attacks/</link>
      <pubDate>Tue, 10 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/build/mitm_attacks/</guid>
      <description>&lt;p&gt;having gained some knowhow of network security, i thought it was time to do some cool shit — let the hacking begin!&lt;/p&gt;
&lt;p&gt;i came across a video by network chuck on sniffing packets, by executing what is known as a man in the middle attack, and decided to do it myself.&lt;/p&gt;
&lt;p&gt;mitm allows us to sniff all network packets being sent from a device to the router and vice-versa.&lt;/p&gt;
&lt;p&gt;essentially, how this attack works is by bluffing your router into believing that your (the hacker’s) device is the target device and the target device into believing that your (the hacker’s) device is the router. this happens through arp (address resolution protocol) poisoning.&lt;/p&gt;</description>
      <content>&lt;p&gt;having gained some knowhow of network security, i thought it was time to do some cool shit — let the hacking begin!&lt;/p&gt;
&lt;p&gt;i came across a video by network chuck on sniffing packets, by executing what is known as a man in the middle attack, and decided to do it myself.&lt;/p&gt;
&lt;p&gt;mitm allows us to sniff all network packets being sent from a device to the router and vice-versa.&lt;/p&gt;
&lt;p&gt;essentially, how this attack works is by bluffing your router into believing that your (the hacker’s) device is the target device and the target device into believing that your (the hacker’s) device is the router. this happens through arp (address resolution protocol) poisoning.&lt;/p&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
&lt;div class=&#34;mermaid&#34;&gt;
flowchart LR
A[&#34;router&#34;]---&gt;|&#34;packet&#34;|B[&#34;your device&#34;]---&gt;|&#34;packet&#34;|C[&#34;target device&#34;]
C[&#34;target device&#34;]---&gt;|&#34;packet&#34;|B[&#34;your device&#34;]---&gt;|&#34;packet&#34;|A[&#34;router&#34;]
&lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;so now, every packet that was supposed to be sent to the router to be further forwarded to the internet now firstly goes through your device which then forwards it to the router to be sent further, and everything coming from the internet through the router firstly enters your device and then is forwarded to the target device.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;executing it out:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;i need three major tools for this -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nmap: for fixing my crosshair on the target — analysing the network and identifying the connected devices&lt;/li&gt;
&lt;li&gt;ettercap: for executing arp poisioning&lt;/li&gt;
&lt;li&gt;wireshark: for analysing the packets being exchanged&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;getting my private ip -&lt;/p&gt;
&lt;p&gt;ran ifconfig, got a huge response, out of which the ‘en0’ part is important:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;why en0? because that is used to refer to your wifi interface (en1 is used for lan)(generally).&lt;/p&gt;
&lt;p&gt;what can we gauge out of this? -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ether&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%201.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;this is my device’s mac address&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;inet6&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%202.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;this is my local ipv6 address&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;inet&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%203.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;this gives a bunch of information. 192.168.1.6 is my local ipv4 address.&lt;/p&gt;
&lt;p&gt;0xffffff00 is the netmask, which is in hex format. we’ll convert this into the 8bit format. since one hex character is 4 bit (0 to 2^4-1), we divide the hex into groups of 2 to get - ff ff ff 00, which when converted gives 255.255.255.0 - this implies that the first &lt;strong&gt;24&lt;/strong&gt; bits are for the network and the last 8 for devices - .0 to .255&lt;/p&gt;
&lt;p&gt;further .255 is the broadcast address, which means anything directed to .255 is broadcasted to all devices connected to the network. // can some attack happen via this?&lt;/p&gt;
&lt;p&gt;since .0 is reserved for the network id and .255 for broadcast, .1-.254 can be occupied by devices.&lt;/p&gt;
&lt;p&gt;now, how do we get the network subnet?&lt;/p&gt;
&lt;p&gt;the whole ip network - 192.168.0.0/16&lt;/p&gt;
&lt;p&gt;a subnet - 192.168.1.0/24&lt;/p&gt;
&lt;p&gt;a device - 192.168.1.1&lt;/p&gt;
&lt;p&gt;// the part after ‘/’ implies the number of bits saved for the network.&lt;/p&gt;
&lt;p&gt;so our subnet is 192.168.1.0/24&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;enumeration -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ran the follwoing nmap command to view a list of devices connected to my network and list the open/closed ports associated with that device.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo nmap -sN &amp;lt;subnet_for_my_home_network&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;the flag -sN implies a stealth TCP null scan, ie, it does not use standard TCP flags like SYN, ACK. if the response is none that implies that the port is open. in case the response is RST(reset), it implies that the port is closed. why? because tcp’s rfc says that if a packet does not match the existing connection and does not have a header like SYN or FIN then the system should respond with an RST if the port is closed.&lt;/p&gt;
&lt;p&gt;i got the following response:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/Screenshot_2025-05-26_at_15.07.10.png&#34; alt=&#34;Screenshot 2025-05-26 at 15.07.10.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;this gives me the ip addresses and mac ids of the devices connected on my network&lt;/p&gt;
&lt;p&gt;// on further reading, i understood that a no response doesn’t always necessarily imply that the port is open, it might as well be being blocked by a firewall.&lt;/p&gt;
&lt;p&gt;// i also got to know that i can get the list of devices through the ‘-sn’ flag than the ‘-sN’ flag. the key differences b/w -sn and -sN are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;-sn does a device scan through icmp echo requests (ping), does not scan ports&lt;/li&gt;
&lt;li&gt;-sN scans ports by sending tcp null requests, we get the device info along with port info&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;so then i ran this command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo nmap -sn &amp;lt;subnet_for_my_home_network&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;got the following response:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%204.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;this gives all the devices connected to my network. .9 is my phone (iphone also specified in the previous response), .7 my alexa (says amazon technologies) and .6 is my laptop.&lt;/p&gt;
&lt;p&gt;what’s weird is that other devices connected to my network are not being displayed.&lt;/p&gt;
&lt;p&gt;^^ need to look into this&lt;/p&gt;
&lt;p&gt;let’s attack my phone — ipv4: 192.168.1.9&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;executing the attack&lt;/p&gt;
&lt;p&gt;well executing it is pretty chill, all i have to do is run the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo ettercap -T -S -i en0 -M arp:remote /192.168.1.1// /192.168.1.9//
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;well that’s a very long one, here’s what it all means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-T&lt;/strong&gt;: for text only interface&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-S&lt;/strong&gt;: for sm shi i didnt understand&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-i&lt;/strong&gt;: for specifying the interface&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-M&lt;/strong&gt;: for man in the middle attacks&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;arp:remote /&lt;ip1&gt;// /&lt;ip2&gt;//&lt;/strong&gt;: arp signifies that it must be done via arp spoofing, ip1 is the router’s ip and ip2 the target device’s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;here is what happened after that:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%205.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%206.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;// this is definitely something i couldnt make sense of so i opened it on wireshark.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sniffing the packets via wireshark&lt;/p&gt;
&lt;p&gt;opened wireshark, opened the ‘eth0’ interface, and applied the following filter to see traffic coming in/going out from my phone&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%207.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;i opened &lt;a href=&#34;http://www.youtube.com&#34;&gt;www.youtube.com&lt;/a&gt; on my phone and saw packets being exchanged with 172.217.166.14 which on lookup turned out to be google’s server. the application data was ofc encrypted and i couldnt figure out what it was.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%208.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%209.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;then i tried a few different websites like &lt;a href=&#34;http://amazon.in&#34;&gt;amazon.in&lt;/a&gt; which interacted with a no. of ips all of which belonged to amazon web services.&lt;/p&gt;
&lt;p&gt;but this isnt going to let me find out what exact websites the target is going to.&lt;/p&gt;
&lt;p&gt;provided, they are secured. in case they arent, ie, in the case of http websites (i visited &lt;a href=&#34;http://www.testingmcafeesites.com/&#34;&gt;http://www.testingmcafeesites.com&lt;/a&gt;), you can directly see the application data being transferred in plain text.&lt;/p&gt;
&lt;p&gt;i added the following filter to see only http protocol packets:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2010.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;then followed the http stream of the latest one&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/e938b04f-1de0-4544-af88-44fa6fba3905.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;and got this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2011.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;^^ this essentially gives away the entire response being returned from the site in plain text. this is why http isnt secure.&lt;/p&gt;
&lt;p&gt;another way to get to know about the websites being visited is by looking at the dns requests. i updated the filter to only view dns requests and visited instagram, my personal webpage, and - uhm - a little questionable site.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2012.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;then i visited patrick collisions &lt;a href=&#34;https://patrickcollison.com/advice&#34;&gt;advice&lt;/a&gt; and that too is visible.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2013.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;well yea, i guess that’s it for mitm attacks. very fun, but would’ve been better if i’d’ve executed it on a different device than my own phone. will figure out why nmap’s not showing other devices and see what could be done to fix that.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;update-&lt;/p&gt;
&lt;p&gt;i found a better way to do this and that is by using bettercap. just the commands used change, the basic principles remain the same.&lt;/p&gt;
&lt;p&gt;there’s no need for nmap now as bettercap itself can show me the devices connected to my router.&lt;/p&gt;
&lt;p&gt;sudo bettercap —&amp;gt; net.probe on —&amp;gt; net.show&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2014.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mitm_attacks/image%2015.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;then go over to wireshark to analyse the packets.&lt;/p&gt;
&lt;p&gt;lol i just intercepted my dad’s computer&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>building my own browser</title>
      <link>https://1rvinn.github.io/build/browser/</link>
      <pubDate>Sat, 10 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/build/browser/</guid>
      <description>&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;10/05/25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;i dont know why but recently i’ve been getting this urge to build a browser of my own. something that’s bespoke to my needs - has ai inbuilt, is junk free and everything is the way i want it. yeah maybe if it turns out to be amazing, i may plan on launching it but that’s for me to worry about later.&lt;/p&gt;
&lt;p&gt;i found this &lt;a href=&#34;https://browser.engineering/&#34;&gt;primer&lt;/a&gt; which is in and out of what a browser entails and how to build it on your own.&lt;/p&gt;</description>
      <content>&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;10/05/25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;i dont know why but recently i’ve been getting this urge to build a browser of my own. something that’s bespoke to my needs - has ai inbuilt, is junk free and everything is the way i want it. yeah maybe if it turns out to be amazing, i may plan on launching it but that’s for me to worry about later.&lt;/p&gt;
&lt;p&gt;i found this &lt;a href=&#34;https://browser.engineering/&#34;&gt;primer&lt;/a&gt; which is in and out of what a browser entails and how to build it on your own.&lt;/p&gt;
&lt;p&gt;doing a bit of research, i have realised that it is kinda hard to do it all from scratch, not only because it is going to be very long but also because of the compute inefficiency of the product you’ll get out with - very laggy, sucking all the juice out your ram.&lt;/p&gt;
&lt;p&gt;i could build it on top of chromium, but that wont teach me a lot about browsers and networking.&lt;/p&gt;
&lt;p&gt;so i have decided to do neither and both at the same time. i’ll follow the primer, understand the basics right and then switch over to building over chromium, which i believe is also going to be imperative if i want to integrate ai into it — could be wrong, i dont really know.&lt;/p&gt;
&lt;p&gt;the best thing would still be to do it all from scratch, but let’s see where reading the primer leads me to and then make a decision likewise.&lt;/p&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;[update] 12/06/25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;have built a very bare bones version that can display basic web pages (only text lmao not even html). ik, very far away from my final goal, but i have realised how hard it is to build a browser and definitely wouldn&amp;rsquo;t be able to make the one of my dreams from scratch - will have to capitalise on the chromium infra (now i understand the imp of open source). \
but the process is v.v. cool cuz im learning a hell lot about how the internet functions. it aint all a blackbox anymore.&lt;/p&gt;
&lt;hr&gt;
</content>
    </item>
    
    <item>
      <title>project proposal - federated learning</title>
      <link>https://1rvinn.github.io/crude/project-proposal---federated-learning/</link>
      <pubDate>Tue, 29 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/project-proposal---federated-learning/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;this project aims at exploring a novel framework for training neural networks - federated learning.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;brief-about-federated-learning&#34;&gt;brief about federated learning:&lt;/h4&gt;
&lt;p&gt;traditionally, local availability of training data has been an important pre-requisite for training ml models. however, this methodology has a variety of road blocks associated with it. the prime ones being lack of democratisation in model creation and lower development in fields with sensitive data like finance and healthcare. federated learning aims to solve these challenges by introducing an alternate way of training models - instead of data travelling to the model and the model getting trained, the model travels to data sources (silos, personal devices), gets trained and publishes the updates back to the central model.
this enhances the privacy of ai based systems since the data has to never leave the device. furthermore, this means that people can have full control of their data and yet contirbute tot he development of ai, ie, now proprietary and sensitive data can also be used for training (both pre and post) purposes. this solves the problem of only big data companies being able to train big models, thus leading to more democratization in the field. secondly, it also promotes ai developments in the sensitive data fields like finance and healthcare, which traditionally have been underdeveloped due to privacy concerns.&lt;/p&gt;</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;this project aims at exploring a novel framework for training neural networks - federated learning.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;brief-about-federated-learning&#34;&gt;brief about federated learning:&lt;/h4&gt;
&lt;p&gt;traditionally, local availability of training data has been an important pre-requisite for training ml models. however, this methodology has a variety of road blocks associated with it. the prime ones being lack of democratisation in model creation and lower development in fields with sensitive data like finance and healthcare. federated learning aims to solve these challenges by introducing an alternate way of training models - instead of data travelling to the model and the model getting trained, the model travels to data sources (silos, personal devices), gets trained and publishes the updates back to the central model.
this enhances the privacy of ai based systems since the data has to never leave the device. furthermore, this means that people can have full control of their data and yet contirbute tot he development of ai, ie, now proprietary and sensitive data can also be used for training (both pre and post) purposes. this solves the problem of only big data companies being able to train big models, thus leading to more democratization in the field. secondly, it also promotes ai developments in the sensitive data fields like finance and healthcare, which traditionally have been underdeveloped due to privacy concerns.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.dailydoseofds.com/content/images/2023/11/federated-gif.gif&#34; alt=&#34;federated learning&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a comic by google on the topic: &lt;a href=&#34;https://federated.withgoogle.com/&#34;&gt;https://federated.withgoogle.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;an interactive visualisation covering the basics: &lt;a href=&#34;https://pair.withgoogle.com/explorables/federated-learning/&#34;&gt;https://pair.withgoogle.com/explorables/federated-learning/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;an in depth overview: &lt;a href=&#34;https://queue.acm.org/detail.cfm?id=3501293&#34;&gt;https://queue.acm.org/detail.cfm?id=3501293&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/2107.10976&#34;&gt;https://arxiv.org/pdf/2107.10976&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;a small writeup by me on the importance of FL: &lt;a href=&#34;https://1rvinn.github.io/eureka/fed/&#34;&gt;https://1rvinn.github.io/eureka/fed/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;this project will be an amalgamation of ai and security. focusing in depth on the following topics:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;how models are trained [A]&lt;/li&gt;
&lt;li&gt;working of neural nets [A]&lt;/li&gt;
&lt;li&gt;comparision between traditionally trained nets vs FL trained ones&lt;/li&gt;
&lt;li&gt;networking between devices and a central server [S]&lt;/li&gt;
&lt;li&gt;privacy preserving methodologies and the mathematics involved [S]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A - ai focused topics, S - security focused topics&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;milestones-to-be-achieved&#34;&gt;milestones to be achieved:&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;building the basis (a good part of this can be covered in the app phase) [3 weeks]
&lt;ul&gt;
&lt;li&gt;gain an idea about federated learning (only a high level overview)
&lt;ul&gt;
&lt;li&gt;key steps involved:
&lt;ul&gt;
&lt;li&gt;client selection&lt;/li&gt;
&lt;li&gt;model distribution&lt;/li&gt;
&lt;li&gt;update upload&lt;/li&gt;
&lt;li&gt;aggregation, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/blog-series/privacy-preserving&#34;&gt;understanding privacy considerations&lt;/a&gt;:
&lt;ul&gt;
&lt;li&gt;model update attacks&lt;/li&gt;
&lt;li&gt;trained model attacks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;current applications in the industry, future prospects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;start off by implementing it on ml models, using already existing frameworks like &lt;a href=&#34;https://flower.ai/&#34;&gt;flower&lt;/a&gt;/&lt;a href=&#34;https://developer.nvidia.com/flare&#34;&gt;nvidia flare&lt;/a&gt; [2 weeks]
&lt;ul&gt;
&lt;li&gt;understanding the library&lt;/li&gt;
&lt;li&gt;implement on a basic ml model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;delving deeper
&lt;ul&gt;
&lt;li&gt;understanding fl in greater detail [3 months]
&lt;ul&gt;
&lt;li&gt;comprehensively understand the maths behind it&lt;/li&gt;
&lt;li&gt;exploring different training methods like FedAvg, FedSGD etc.&lt;/li&gt;
&lt;li&gt;security considerations
&lt;ul&gt;
&lt;li&gt;secure aggregation&lt;/li&gt;
&lt;li&gt;differential privacy&lt;/li&gt;
&lt;li&gt;homomorphic encryption&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;modeling federated learning from scratch
&lt;ul&gt;
&lt;li&gt;coding the process from scratch, including all the above stated steps (&amp;lsquo;key steps involved&amp;rsquo;)&lt;/li&gt;
&lt;li&gt;implementing &amp;gt;=1 privacy preserving strategies (secure agg, diff priv., homo enc)&lt;/li&gt;
&lt;li&gt;facilitating networking between edge devices and a central server&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;implementation:
&lt;ul&gt;
&lt;li&gt;implement on the following networks (subject to change on the basis of our findings above): [3 months]
&lt;ul&gt;
&lt;li&gt;CNNs&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.09943&#34;&gt;SLMs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;implement using existing libraries first [to be displayed in RC] and later from scratch.&lt;/li&gt;
&lt;li&gt;compare their accuracies with that of normally trained neural nets [to be displayed in RC]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;look into fine-tuning llms for particular tasks using FL
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2409.05976&#34;&gt;FLoRA&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2102.00875&#34;&gt;https://arxiv.org/abs/2102.00875&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;this could be one of the first steps towards making specialised chatbots (possibly even agents) trained on personal private data (great financial use case).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;further improvements
&lt;ul&gt;
&lt;li&gt;coming up with solutions to the bottlenecks identified&lt;/li&gt;
&lt;li&gt;a few unique approaches include
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.alphaxiv.org/abs/2209.06359v1&#34;&gt;federated pruning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2102.03448&#34;&gt;federated reconstruction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;federated dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;future prospects
&lt;ul&gt;
&lt;li&gt;publishing our own library for federated learning - simplifying tasks like secure aggregation, differential privacy etc.&lt;/li&gt;
&lt;li&gt;an api based federated learning model which people can opt into for training
&lt;ul&gt;
&lt;li&gt;eg:  small financial institutions can opt-in to train anti-fraud or loan default prediction models collaboratively.&lt;/li&gt;
&lt;li&gt;hospitals signing up to develop privacy preserving diagnostic models. &lt;a href=&#34;https://aibusiness.com/verticals/intel-and-upenn-to-use-federated-ai-for-privacy-preserving-brain-tumor-research#:~:text=Instead%20of%20moving%20data%20to,into%20a%20single%2C%20larger%20model&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;creating an agent specialized for a particular task - financial analysis, tax filing agents.&lt;/li&gt;
&lt;li&gt;^ requires collaborations with financial institutions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>on webrtc</title>
      <link>https://1rvinn.github.io/crude/webrtc/</link>
      <pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/webrtc/</guid>
      <description>&lt;p&gt;got to know about a very interesting framework today - the webrtc. it is a google developed method that facilitates exchange of data and information between browsers by establishing a web p2p connection. and the best part about it is that it doesn’t require a server to transfer data. yes, it does require one to establish the newtork but that’s it. after the connection is setup, all transfer happens from the sender’s browser to the receiver’s without the play of any server in between. crazy innit? there have been a few implementations of this framework - browser to browser chat, video call and, the most interesting of them all, file transfer. there is a project called file.pizza which saves data and time by reducing the 2 step - upload, download cycle to a single step - transfer. only when the receiver requests for the file does the file gets transfered. no need to upload it to a mutually accessible place and downloading it, rather just get your unique file pizza link and share it over to the person accessing the file. however, a few drawbacks of this include the sender having to keep the link open until the receiver dowloads it and having to repeat the process over again everytime you want someone to download it, since the link gets terminated with the session’s end. it is but, at the end of the day, an interesting approach. i’m thinking of other applications of this, there are certain very intuitive ones - texting, video, mails - the entire sphere of information transfer - which is better this way by virtue of low data requirement and more security due to the lack of a central sever (kinda unsure about this point since there could always be attacks on the way). but these are only the very basic implementations of the framework. there has to be something novel, something that can leverage this platform to solve a bigger issue. [TBC]&lt;/p&gt;</description>
      <content>&lt;p&gt;got to know about a very interesting framework today - the webrtc. it is a google developed method that facilitates exchange of data and information between browsers by establishing a web p2p connection. and the best part about it is that it doesn’t require a server to transfer data. yes, it does require one to establish the newtork but that’s it. after the connection is setup, all transfer happens from the sender’s browser to the receiver’s without the play of any server in between. crazy innit? there have been a few implementations of this framework - browser to browser chat, video call and, the most interesting of them all, file transfer. there is a project called file.pizza which saves data and time by reducing the 2 step - upload, download cycle to a single step - transfer. only when the receiver requests for the file does the file gets transfered. no need to upload it to a mutually accessible place and downloading it, rather just get your unique file pizza link and share it over to the person accessing the file. however, a few drawbacks of this include the sender having to keep the link open until the receiver dowloads it and having to repeat the process over again everytime you want someone to download it, since the link gets terminated with the session’s end. it is but, at the end of the day, an interesting approach. i’m thinking of other applications of this, there are certain very intuitive ones - texting, video, mails - the entire sphere of information transfer - which is better this way by virtue of low data requirement and more security due to the lack of a central sever (kinda unsure about this point since there could always be attacks on the way). but these are only the very basic implementations of the framework. there has to be something novel, something that can leverage this platform to solve a bigger issue. [TBC]&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>mindpalace</title>
      <link>https://1rvinn.github.io/build/mindpalace/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/build/mindpalace/</guid>
      <description>&lt;hr&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
    &lt;h3 style=&#34;color: #23affd;&#34;&gt; // the final thing &lt;/h3&gt;
&lt;p&gt;find it hard to understand long github repos and pdfs?&lt;/p&gt;
&lt;p&gt;struggle no more, just enter your mindpalace.&lt;/p&gt;
&lt;p&gt;mindpalace helps you understand the repo/pdf visually by providing concise explanations along with mindmaps. and the ask ai feature allows you to ask anything about it. hop into your mindpalace - understand visually, understand better&lt;/p&gt;
&lt;p&gt;try it out here: &lt;a href=&#34;https://mindpalace.streamlit.app&#34;&gt;https://mindpalace.streamlit.app&lt;/a&gt;&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/SyELL3N9h5c?si=zy4PU5eZPHyrX7sg&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
    &lt;br&gt;
    &lt;h3 style=&#34;color: #23affd;&#34;&gt; // building it out - the journey&lt;/h3&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;the idea:&lt;/strong&gt;
the user should be able to input pdf(s) which get converted into mindmaps for easy learning. the same should be done for github repos. in addition, there should be an llm to ask questions. &lt;br&gt;
useful for neurodiverse people; facilitates better learning for them&lt;/p&gt;</description>
      <content>&lt;hr&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
    &lt;h3 style=&#34;color: #23affd;&#34;&gt; // the final thing &lt;/h3&gt;
&lt;p&gt;find it hard to understand long github repos and pdfs?&lt;/p&gt;
&lt;p&gt;struggle no more, just enter your mindpalace.&lt;/p&gt;
&lt;p&gt;mindpalace helps you understand the repo/pdf visually by providing concise explanations along with mindmaps. and the ask ai feature allows you to ask anything about it. hop into your mindpalace - understand visually, understand better&lt;/p&gt;
&lt;p&gt;try it out here: &lt;a href=&#34;https://mindpalace.streamlit.app&#34;&gt;https://mindpalace.streamlit.app&lt;/a&gt;&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/SyELL3N9h5c?si=zy4PU5eZPHyrX7sg&#34; title=&#34;YouTube video player&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;br&gt;
&lt;br&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
    &lt;br&gt;
    &lt;h3 style=&#34;color: #23affd;&#34;&gt; // building it out - the journey&lt;/h3&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;the idea:&lt;/strong&gt;
the user should be able to input pdf(s) which get converted into mindmaps for easy learning. the same should be done for github repos. in addition, there should be an llm to ask questions. &lt;br&gt;
useful for neurodiverse people; facilitates better learning for them&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;inspirations:&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;  1. docagram &lt;/summary&gt;
&lt;p&gt;creates flow-chart summaries from web pages&lt;/p&gt;
&lt;p&gt;flow:
&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;takes in data from web page sections&lt;/li&gt;
&lt;li&gt;creates a summary of each of those sections&lt;/li&gt;
&lt;li&gt;generates relationships between parts of the section&lt;/li&gt;
&lt;li&gt;has 2 versions -
&lt;ul&gt;
&lt;li&gt;w/o gemini: uses summarizer api and prompt api for the 2 tasks respectively&lt;/li&gt;
&lt;li&gt;w/ gemini&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;content:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%201.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;summary:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%202.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;summary v2 (used to generate the graph)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%203.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;graph/mermaid diagram:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%204.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;a shaded box displays the relationship, the unfilled boxes are entities&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;gemini result&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%205.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;also have the ability to display all graphs together, can choose specific entitites to show as well if someone wants to learn topic wise&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt; 2. better learning for neurodiverse ppl&lt;/summary&gt;
medium article - https://medium.com/@elle.neal_71064/mind-mapping-with-ai-an-accessible-approach-for-neurodiverse-learners-1a74767359ff
&lt;/details&gt;
&lt;p&gt;can build upon these&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;19/02/25 initial plan:&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
    &lt;div class=&#34;mermaid&#34;&gt;

    flowchart TD
        A[document]---&gt;|segmentor|B[segments of data]---&gt;|summarizer|D[summarized segments of data]---&gt;|relationship determiner|E[mermaid diagram]
        A---&gt;C[rag]---&gt;F[llm]
        D---&gt;E
    &lt;/div&gt;

&lt;/div&gt;
&lt;p&gt;// want to create it on streamlit since minimal ui, simpler coding&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;update 1 (19/2/25):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;i feel like i should pivot this towards github. a tool that facilitates understanding of complex repos through mindmap generation and llm integration&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for github repo, i need to parse the contents into an llm acceptable format. there are tools doing that already. i am not sure whether to use them/their apis or develop it completely on my own.
&lt;ul&gt;
&lt;li&gt;one of the ideas i came across recently was that of &lt;a href=&#34;https://www.entelligence.ai/explore&#34;&gt;entelligence.ai&lt;/a&gt; - they take in repos, integrate an llm, provide documentation and flow diagram.
&lt;ul&gt;
&lt;li&gt;the llm responses are really good - looks finetuned (??)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;maybe have both options - github and documents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;multimodal support is crucial - it should be able to take in documents, pictures,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&#34;reading--trying-out-stuff&#34;&gt;reading &amp;amp; trying out stuff&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;(1) should i use beautiful soup to scrap github repo data? prolly not gonna work but never used it so lemme try it out once.&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;trying out beautiful soup &lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;(referring to https://medium.com/@elle.neal_71064/mind-mapping-with-ai-an-accessible-approach-for-neurodiverse-learners-1a74767359ff)

python code:

```python
import requests
from bs4 import BeautifulSoup

def scrape_text(url):
    # Send a GET request to the URL
    response = requests.get(url)

    # If the GET request is successful, the status code will be 200
    if response.status_code == 200:
        # Get the content of the response
        page_content = response.content

        # Create a BeautifulSoup object and specify the parser
        soup = BeautifulSoup(page_content, &amp;quot;html.parser&amp;quot;)

        # Get the text of the soup object
        text = soup.get_text()

        # Return the text
        return text
    else:
        return &amp;quot;Failed to scrape the website&amp;quot;

url=input(&amp;quot;enter url:&amp;quot;)
text=scrape_text(url)
print(text)
```

returns text in the website.
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;ul&gt;
&lt;li&gt;didn&amp;rsquo;t try it on github repos, can make it work somehow, will be hard tho. will look into it later.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;(2) how did this guy make the functionality?&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;reading this medium article&lt;/summary&gt;
https://medium.com/@elle.neal_71064/mind-mapping-with-ai-an-accessible-approach-for-neurodiverse-learners-1a74767359ff
&lt;/details&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;they’ve given the entire &lt;em&gt;input_text&lt;/em&gt; received after parsing to the model and asked to generate mermaid maps&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;i want mine to be better - it should generate summaries and mermaids for each section, determine the relation among the sections and generate a cohesive mermaid also&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;(3) checking how good chat gpt is with giving mermaid diags&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt; this section&#39;s gonna be long, tried out a variety of inputs and prompts&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;asked chatgpt to analyse my repo - via the repo link - and asked to give a mermaid code explaining it
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;output:&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
      &lt;div class=&#34;mermaid&#34;&gt;
            graph TD
                A[Start] --&gt; B[Load Configuration]
                B --&gt; C[Read Input Data: Orders &amp; Locations]
                C --&gt; D[Fetch Route Data from APIs]
                D --&gt; E[Optimize Routes using Held-Karp Algorithm]
                E --&gt; F[Calculate Emissions Based on Route]
                F --&gt; G[Generate Optimized Route and Emissions Report]
                G --&gt; H[Display Output to User]
                H --&gt; I[End]
                
                %% Dependencies
                D --&gt;|API Calls| J{TomTom API / HERE API}
                J --&gt; D
            &lt;/div&gt;

  &lt;/div&gt;
  the output aint bad
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;then i used &lt;a href=&#34;https://gitingest.com/&#34;&gt;gitingest&lt;/a&gt; to get llm ready parseed version of my repo. gave it as context to gpt4o and asked it to give a mermaid code.&lt;/p&gt;
&lt;p&gt;prompt: [llm ready parsed info (token length - 4.7k)] given the above description of a repository, write code for a mermaid diagram explaining the same&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;output:&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
      &lt;div class=&#34;mermaid&#34;&gt;
                graph TD;
                    A[Repository: 1rvinn-fedexpedite] --&gt;|Contains| B[README.md]
                    A --&gt;|Contains| C[app.py]
                    A --&gt;|Contains| D[requirements.txt]
                    A --&gt;|Contains| E[images/]
                    A --&gt;|Contains| F[.streamlit/]
                    F --&gt; G[config.toml]
                    
                    subgraph &#34;Core Files&#34;
                        B --&gt;|Provides| B1[Project Overview &amp; Setup Instructions]
                        C --&gt;|Main Application| C1[Route Optimiser &amp; Emission Calculator]
                        D --&gt;|Dependencies| D1[Streamlit, Folium, Requests, Streamlit Folium]
                        E --&gt;|Contains| E1[Visual Assets - Screenshots, Diagrams]
                        G --&gt;|Defines| G1[Streamlit Theme &amp; UI Customisation]
                    end
                
                    subgraph &#34;Application Workflow&#34;
                        C1 --&gt;|Receives API Keys| H[TomTom API, HERE API]
                        C1 --&gt;|Takes Inputs| I[Route Preferences, Vehicle Type, Fuel Type]
                        I --&gt;|Uses| J[Held-Karp Algorithm for Optimisation]
                        J --&gt;|Outputs| K[Optimal Route, Travel Time, Emission Data]
                        K --&gt;|Visualised in| L[Google Maps, Folium Map]
                    end
                
                &lt;/div&gt;

  &lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;maybe ask it to give 2 separate diagrams for directory structure and code logic.&lt;/p&gt;
&lt;p&gt;prompt: give 2 separate codes - one explaining the directory structure and the other explaining the code, logic and flow&lt;/p&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;og output: has errors&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
      &lt;div class=&#34;mermaid&#34;&gt;
                        &lt;div class=&#34;mermaid&#34;&gt;
                        graph TD;
                            %% Directory Structure
                            subgraph &#34;Repository Structure&#34;
                                A[Repository: 1rvinn-fedexpedite] --&gt;|Contains| B[README.md]
                                A --&gt;|Contains| C[app.py]
                                A --&gt;|Contains| D[requirements.txt]
                                A --&gt;|Contains| E[images/]
                                A --&gt;|Contains| F[.streamlit/]
                                F --&gt; G[config.toml]
                            end
                        
                            subgraph &#34;Core Files&#34;
                                B --&gt;|Provides| B1[Project Overview &amp; Setup Instructions]
                                C --&gt;|Main Application| C1[Route Optimiser &amp; Emission Calculator]
                                D --&gt;|Dependencies| D1[Streamlit, Folium, Requests, Streamlit Folium]
                                E --&gt;|Contains| E1[Visual Assets (Screenshots, Diagrams)]
                                G --&gt;|Defines| G1[Streamlit Theme &amp; UI Customisation]
                            end
                        &lt;/div&gt;

                
                        &lt;div class=&#34;mermaid&#34;&gt;
                        graph TD;
                            %% Application Logic and Flow
                            A[User Input] --&gt;|Enter Route Details| B[Start Location &amp; Stops]
                            B --&gt;|Fetch Coordinates| C[HERE API]
                            B --&gt;|Select Vehicle Type| D[Emission Factors Calculation]
                            
                            subgraph &#34;Route Calculation&#34;
                                C --&gt;|Compute Routes| E[TomTom API]
                                E --&gt;|Applies| F[Held-Karp Algorithm]
                                F --&gt;|Outputs| G[Optimised Route &amp; Travel Time]
                            end
                            
                            subgraph &#34;Emissions Calculation&#34;
                                D --&gt;|Compute Emissions| H[Vehicle Type, Engine Size, Fuel Type]
                                H --&gt;|Uses Data| I[India GHG Emission Factors]
                                I --&gt;|Outputs| J[Total Emissions (kg CO₂)]
                            end
                            
                            subgraph &#34;Visualisation &amp; Results&#34;
                                G --&gt;|Displays| K[Google Maps &amp; Folium]
                                J --&gt;|Shows| L[Emissions Output]
                                K &amp; L --&gt;|Final Output| M[User Dashboard]
                            end
                        &lt;/div&gt;

                    &lt;/div&gt;

  &lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output divided into 2&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                
                graph TD;
                    %% Directory Structure
                    subgraph &#34;Repository Structure&#34;
                        A[Repository: 1rvinn-fedexpedite] --&gt;|Contains| B[README.md]
                        A --&gt;|Contains| C[app.py]
                        A --&gt;|Contains| D[requirements.txt]
                        A --&gt;|Contains| E[images/]
                        A --&gt;|Contains| F[.streamlit/]
                        F --&gt; G[config.toml]
                    end
                
                    subgraph &#34;Core Files&#34;
                        B --&gt;|Provides| B1[Project Overview &amp; Setup Instructions]
                        C --&gt;|Main Application| C1[Route Optimiser &amp; Emission Calculator]
                        D --&gt;|Dependencies| D1[Streamlit, Folium, Requests, Streamlit Folium]
                        E --&gt;|Contains| E1[Visual Assets - Screenshots, Diagrams]
                        G --&gt;|Defines| G1[Streamlit Theme &amp; UI Customisation]
                    end
                &lt;/div&gt;

  &lt;/div&gt;
&lt;p&gt;^ this is good.&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                graph TD;
                    %% Application Logic and Flow
                    A[User Input] --&gt;|Enter Route Details| B[Start Location &amp; Stops]
                    B --&gt;|Fetch Coordinates| C[HERE API]
                    B --&gt;|Select Vehicle Type| D[Emission Factors Calculation]
                    
                    subgraph &#34;Route Calculation&#34;
                        C --&gt;|Compute Routes| E[TomTom API]
                        E --&gt;|Applies| F[Held-Karp Algorithm]
                        F --&gt;|Outputs| G[Optimised Route &amp; Travel Time]
                    end
                    
                    subgraph &#34;Emissions Calculation&#34;
                        D --&gt;|Compute Emissions| H[Vehicle Type, Engine Size, Fuel Type]
                        H --&gt;|Uses Data| I[India GHG Emission Factors]
                        I --&gt;|Outputs| J[Total Emissions - kg CO₂]
                    end
                    
                    subgraph &#34;Visualisation &amp; Results&#34;
                        G --&gt;|Displays| K[Google Maps &amp; Folium]
                        J --&gt;|Shows| L[Emissions Output]
                        K &amp; L --&gt;|Final Output| M[User Dashboard]
                    end
                &lt;/div&gt;

  &lt;/div&gt;
&lt;p&gt;^ this one is really detailed. but i’m sure its taking inputs from the readme file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;trying without giving the readme file, as the readme already contains the flow.&lt;/p&gt;
&lt;p&gt;prompt: [llm ready parsed info (token length - 4.7k)] given the above description of a repository, write code for a mermaid diagram explaining the same. give 2 separate codes - one explaining the directory structure and the other explaining the code, logic and flow&lt;/p&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;fixed output&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                graph TD
                    A[1rvinn-fedexpedite]
                    A --&gt; B[app.py]
                    A --&gt; C[requirements.txt]
                    A --&gt; D[images/]
                    A --&gt; E[.streamlit/]
                    E --&gt; F[config.toml]
                &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                flowchart TD
                    A[Start: Streamlit App Initialization]
                    B[Set page configuration &amp; initialize session state - stops, optimal_route]
                    C[Display App Logo]
                    D[Sidebar: Set Route Calculation Parameters - Traffic, etc.]
                    E[Sidebar: Select Vehicle Details - Travel Mode, Car Type, Engine Size, Fuel Type]
                    F[Sidebar: Choose Input Mode - Coordinates or Search for Destination]
                    G{Input Mode Check}
                    H[Enter Starting Location]
                    I[If Search: Call HERE API to fetch coordinates]
                    J[Add Stop - Coordinates/Search and update session state]
                    K[Optional: Input Ending Location - flexible]
                    L[Display Added Stops with option to Clear]
                    M[Click Calculate Optimal Route]
                    N[For each pair of locations: Call TomTom API to get route details]
                    O[Solve the Traveling Salesman Problem using Held-Karp Algorithm]
                    P[Generate Optimal Route Sequence, Total Distance &amp; Travel Time]
                    Q[Align stop names with the optimal sequence]
                    R[Generate Google Maps URL for the route]
                    S[Calculate Emissions based on vehicle and distance]
                    T[Display Results: Sequence, Total Time, Distance, Emissions]
                    U[Visualize Route on a Folium Map with Markers]
                    V[End]
                
                    A --&gt; B
                    B --&gt; C
                    C --&gt; D
                    D --&gt; E
                    E --&gt; F
                    F --&gt; G
                    G -- &#34;Coordinates&#34; --&gt; H
                    G -- &#34;Search&#34; --&gt; I
                    H --&gt; J
                    I --&gt; J
                    J --&gt; K
                    K --&gt; L
                    L --&gt; M
                    M --&gt; N
                    N --&gt; O
                    O --&gt; P
                    P --&gt; Q
                    Q --&gt; R
                    R --&gt; S
                    S --&gt; T
                    T --&gt; U
                    U --&gt; V
                &lt;/div&gt;

  &lt;/div&gt;
&lt;p&gt;^ this is too ass.&lt;/p&gt;
&lt;p&gt;asked to redo, gave this:&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                graph TD;
                    A[Start - Streamlit App] --&gt;|Initialize Session| B[Session State Variables]
                    A --&gt;|Load API Keys| C[TomTom &amp; HERE API Keys]
                    A --&gt;|Set Streamlit Config| D[UI Configuration]
                
                    B --&gt; E[Sidebar Input]
                    E --&gt;|User Inputs Start Location| F[Fetch Coordinates via HERE API]
                    E --&gt;|User Inputs Stops| G[Add Stops]
                    E --&gt;|User Selects Vehicle Type| H[Emission Calculation Parameters]
                    E --&gt;|User Clicks Calculate Route| I[Calculate Optimal Route]
                
                    I --&gt; J[Calculate Route using TomTom API]
                    J --&gt; K[Solve TSP for Optimal Path]
                    K --&gt; L[Store Optimal Route in Session State]
                
                    L --&gt; M[Display Results]
                    M --&gt;|Show Route Sequence| N[Show Optimal Stops]
                    M --&gt;|Show Travel Time &amp; Distance| O[Calculate Emissions]
                    M --&gt;|Show Google Maps Link| P[Generate Google Maps URL]
                    M --&gt;|Display Route on Folium Map| Q[Render Map with Start, Stops, and End]
                
                    Q --&gt; R[End - Streamlit App]
                    
                &lt;/div&gt;

  &lt;/div&gt;
&lt;p&gt;^ still ass.&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
                graph TD;
                    A[Start - Streamlit App] --&gt;|Initialize Session| B[Session State Variables]
                    A --&gt;|Load API Keys| C[TomTom &amp; HERE API Keys]
                    A --&gt;|Set Streamlit Config| D[UI Configuration]
                
                    B --&gt; E[Sidebar Input]
                    E --&gt;|User Inputs Start Location| F[Fetch Coordinates via HERE API]
                    E --&gt;|User Inputs Stops| G[Add Stops]
                    E --&gt;|User Selects Vehicle Type| H[Emission Calculation Parameters]
                    E --&gt;|User Clicks Calculate Route| I[Calculate Optimal Route]
                
                    I --&gt; J[Calculate Route using TomTom API]
                    J --&gt; K[Solve TSP for Optimal Path]
                    K --&gt; L[Store Optimal Route in Session State]
                
                    L --&gt; M[Display Results]
                    M --&gt;|Show Route Sequence| N[Show Optimal Stops]
                    M --&gt;|Show Travel Time &amp; Distance| O[Calculate Emissions]
                    M --&gt;|Show Google Maps Link| P[Generate Google Maps URL]
                    M --&gt;|Display Route on Folium Map| Q[Render Map with Start, Stops, and End]
                
                    Q --&gt; R[End - Streamlit App]
                &lt;/div&gt;

  &lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;ul&gt;
&lt;li&gt;the outputs were sub standard despite using a sota model - 4o which has a big context window.&lt;/li&gt;
&lt;li&gt;when i use an api, the output’s quality is bound to degrade.&lt;/li&gt;
&lt;li&gt;the token size is also something that should be taken care of; some repos are excessively big and hence really big token sizes which would be hard to handle.&lt;/li&gt;
&lt;li&gt;therefore, it is of utmost importance to divide the content into sections, provide summaries for each part and then ask the model to create a diagram.
&lt;ul&gt;
&lt;li&gt;need to test this hypothesis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;getting started with the real shit now&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;code to get llm ready parsed github data&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;using requests and base 64, got the following code running that prints the contents of a github repo given its name and the owner’s name. uses github api for it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; base64
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# GitHub repository details &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;BASE_URL &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://api.github.com/repos/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;OWNER&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;REPO&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/contents&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fetch_repo_contents&lt;/span&gt;(path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Recursively fetches all files in the GitHub repository.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;BASE_URL&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;path&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; path &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; BASE_URL
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    headers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Authorization&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;token &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;GITHUB_TOKEN&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;} &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; GITHUB_TOKEN &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;headers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;status_code &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;json()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Error fetching &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;url&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;status_code&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_file_content&lt;/span&gt;(file_url):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Fetches and decodes the content of a file from GitHub.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    headers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Authorization&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;token &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;GITHUB_TOKEN&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;} &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; GITHUB_TOKEN &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    response &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; requests&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(file_url, headers&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;headers)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;status_code &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;200&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        file_data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;json()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; file_data&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; base64&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b64decode(file_data[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;utf-8&amp;#34;&lt;/span&gt;, errors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ignore&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; content
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Error fetching file content: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;response&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;status_code&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;traverse_repo&lt;/span&gt;(path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Recursively traverses the GitHub repository and prints file contents.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    items &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; fetch_repo_contents(path)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; items:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; item &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; items:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;file&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;📄 File: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;path&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                content &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_file_content(item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;url&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--- START OF &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; ---&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(content[:&lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;])  &lt;span style=&#34;color:#75715e&#34;&gt;# Print first 1000 chars for preview&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;--- END OF &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;name&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt; ---&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;dir&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;📂 Directory: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;path&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                traverse_repo(item[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;path&amp;#34;&lt;/span&gt;])  &lt;span style=&#34;color:#75715e&#34;&gt;# Recursive call for directories&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Run the script&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;📂 Fetching repository contents for &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;OWNER&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;REPO&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;...&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;traverse_repo()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;^ need to make the following changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; need to change this to take in a url&lt;/p&gt;
&lt;p&gt;must have ‘https://github.com/’ in the beginning - a possible scope of error&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; currently, it’s also printing image and hidden files/directories’ data, which it should skip&lt;/p&gt;
&lt;p&gt;^ excluded the following extensions:&lt;/p&gt;
&lt;p&gt;.png, .jpg, .jpeg, .gif, .svg, .ico, .webp, .pdf, .zip, .tar, .gz, .mp4, .mp3, .avi&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; need it to also print the structure on top&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; must also print that it has exited a directory&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;issue: github api has a limited no. of requests (60) per hour per ip.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one request is used per file/directory accessed&lt;/li&gt;
&lt;li&gt;how to bypass this!!!!!!!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;update 10/3/25: lol i just had to pass my github auth token and the no of requests per hour increases from 60 to 5000&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;divide it into sections (or files); llm provides a technical summary of each section (or file); then these summaries and the structure is fed into the system to analyse the contents and give a mermaid diagram&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can we integrate rag so that it’s able to refer to specifics within the code for a more detailed diagram.&lt;/p&gt;
&lt;p&gt;^ dont really think this is required, since the mermaid diagram is only aimed at providing a high level summary of how the entire code works.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can have mermaid diagrams per section (or file), then one combining them too&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;this kind of ui looks really good. plus if the creation could be animated then would look very cool.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://1rvinn.github.io/img/build/mindpalace/image%206.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[24/2/25]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;work on segmenter, summarizer, relation determiner and mermaid diag generator first.&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    flowchart 
    A[user input]---&gt;B[pdf]---&gt;|parser - ocr/text extractor|E[segmentor]
    A---&gt;C[text]---&gt;E
    A---&gt;D[url]---&gt;|parser - beautiful soup/selenium|E
    A---&gt;K[github repo]---&gt;|repo parser - graphql or gitingest|C[text]
    E---&gt;|topic-wise segmented text packets|F[summarizer]
    F---&gt;|topic-wise summarized packets|G[relationship determiner]---&gt;H---&gt;I[combined mermaid diag]
    F---&gt;|summarized text per topic|H[mermaid diagram generator]---&gt;J[individual mermaid diagrams]
    &lt;/div&gt;

  &lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;random idea but how would an ai model architecture visualizer be?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;code for ssrg:&lt;/strong&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;iter 1&lt;/summary&gt;
    - used this code
&lt;pre&gt;&lt;code&gt;    ```python
    import os
    import re
    import google.generativeai as genai
    import json
    
    genai.configure(api_key=os.environ[&amp;quot;GEMINI_API_KEY&amp;quot;])
    
    # Create the model
    generation_config = {
        &amp;quot;temperature&amp;quot;: 1,
        &amp;quot;top_p&amp;quot;: 0.95,
        &amp;quot;top_k&amp;quot;: 40,
        &amp;quot;max_output_tokens&amp;quot;: 8192,
        &amp;quot;response_mime_type&amp;quot;: &amp;quot;text/plain&amp;quot;,
    }
    
    def extract_json(text):
        &amp;quot;&amp;quot;&amp;quot;Extracts valid JSON from Gemini API response.&amp;quot;&amp;quot;&amp;quot;
        match = re.search(r&amp;quot;\{.*\}&amp;quot;, text, re.DOTALL)  # Find JSON inside { ... }
        if match:
            return match.group(0)  # Return only the JSON part
        return None
    
    def ss(text):
        model1 = genai.GenerativeModel(
        model_name=&amp;quot;gemini-2.0-flash&amp;quot;,
        generation_config=generation_config,
        system_instruction=&amp;quot;You are an AI that extracts key topics from text and summarizes them.\n\n    - Identify the major topics.\n    - Provide a 2-3 sentence summary per topic.\n    - Return results in JSON format:\n    \n    {{\n      \&amp;quot;topics\&amp;quot;: [\n        {{\&amp;quot;topic\&amp;quot;: \&amp;quot;Topic 1\&amp;quot;, \&amp;quot;summary\&amp;quot;: \&amp;quot;Summary of topic 1\&amp;quot;}},\n        {{\&amp;quot;topic\&amp;quot;: \&amp;quot;Topic 2\&amp;quot;, \&amp;quot;summary\&amp;quot;: \&amp;quot;Summary of topic 2\&amp;quot;}}\n      ]\n    }} \n**output only JSON in plaintext format, nothing else&amp;quot;,
        )
    
        chat_session = model1.start_chat(
        history=[
        ]
        )
        response = chat_session.send_message(text)
    
        return response.text
    
    def relation(summary):
        model2 = genai.GenerativeModel(
        model_name=&amp;quot;gemini-2.0-flash&amp;quot;,
        generation_config=generation_config,
        system_instruction=&amp;quot;You are an AI that identifies relationships between topics.\n\n    Given this JSON data of topics, determine relevant relationships:\n    \n    JSON Data: {segmented_data}\n    \n    Output format:\n    {{\n      \&amp;quot;relationships\&amp;quot;: [\n        {{\&amp;quot;from\&amp;quot;: \&amp;quot;Topic 1\&amp;quot;, \&amp;quot;to\&amp;quot;: \&amp;quot;Topic 2\&amp;quot;, \&amp;quot;relationship\&amp;quot;: \&amp;quot;How they are related\&amp;quot;}},\n        {{\&amp;quot;from\&amp;quot;: \&amp;quot;Topic 2\&amp;quot;, \&amp;quot;to\&amp;quot;: \&amp;quot;Topic 3\&amp;quot;, \&amp;quot;relationship\&amp;quot;: \&amp;quot;Another connection\&amp;quot;}}\n      ]\n    }} \n**output only JSON, nothing else**&amp;quot;,
        )
    
        chat_session = model2.start_chat(
        history=[
        ]
        )
    
        response = chat_session.send_message(summary)
        return response.text
    
    def generate_mermaid_code(topics_json, relationships_json):
        topics = json.loads(topics_json)[&amp;quot;topics&amp;quot;]
        relationships = json.loads(relationships_json)[&amp;quot;relationships&amp;quot;]
    
        mermaid_code = &amp;quot;graph TD;\n&amp;quot;
    
        # Add topics as nodes
        for i, topic in enumerate(topics):
            mermaid_code += f&#39;  {chr(65+i)}[&amp;quot;{topic[&amp;quot;topic&amp;quot;]}&amp;quot;];\n&#39;
    
        # Add relationships as edges
        for relation in relationships:
            from_topic = relation[&amp;quot;from&amp;quot;]
            to_topic = relation[&amp;quot;to&amp;quot;]
            relation_text = relation[&amp;quot;relationship&amp;quot;]
    
            from_id = next(i for i, t in enumerate(topics) if t[&amp;quot;topic&amp;quot;] == from_topic)
            to_id = next(i for i, t in enumerate(topics) if t[&amp;quot;topic&amp;quot;] == to_topic)
    
            mermaid_code += f&#39;  {chr(65+from_id)} --&amp;gt;|{relation_text}| {chr(65+to_id)};\n&#39;
    
        return mermaid_code
    
    # def generate_mind_map(text):
    #     segmented_data = ss(text)
    #     relationships_data = relation(segmented_data)
    #     mermaid_diagram = generate_mermaid_code(segmented_data, relationships_data)
    
    #     return mermaid_diagram
    
    if __name__ == &amp;quot;__main__&amp;quot;:
        input_text = input(&amp;quot;input: &amp;quot;)
        
        segmented_data = extract_json(ss(input_text))
        print(f&amp;quot;1: {segmented_data}&amp;quot;)
        relationships_data = extract_json(relation(segmented_data))
        print(f&amp;quot;w: {relationships_data}&amp;quot;)
        mermaid_diagram = generate_mermaid_code(segmented_data, relationships_data)
    
        print(&amp;quot;Generated Mermaid Diagram:\n&amp;quot;)
        print(mermaid_diagram)
    ```
    
    input:
    
    ```
    Artificial Intelligence is revolutionizing industries.
    In healthcare, AI assists with diagnostics and personalized treatments.
    In finance, AI helps detect fraud and optimize trading strategies.
    Machine learning models power these applications, improving accuracy.
    ```
    
    output:
    
    &amp;lt;div style=&#39;text-align:center;&#39;&amp;gt;
    &lt;div class=&#34;mermaid&#34;&gt;
        graph TD;
            A[&#34;AI Revolutionizing Industries&#34;];
            B[&#34;AI in Healthcare&#34;];
            C[&#34;AI in Finance&#34;];
            B --&gt;|AI in Healthcare is a specific application area contributing to the broader AI Revolution across various industries.| A;
            C --&gt;|AI in Finance is a specific application area contributing to the broader AI Revolution across various industries.| A;
            B --&gt;|Both topics represent specific examples of how AI is applied in different sectors to improve efficiency and decision-making through data analysis.| C;
        &lt;/div&gt;

    &amp;lt;/div&amp;gt;
    
    thoughts:
    
    - it identifies major topics well
    - relationships are mid
    - there is no particular flow to it
- prompts
    1. summarizer and segmentor

&amp;lt;div style=&#39;text-align:center;&#39;&amp;gt;
&lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Introduction and Applicability&#34;];
        B[&#34;General Controls: Governance and Management of Security Risks&#34;];
        A --&gt;|The &#39;Introduction and Applicability&#39; section sets the scope and effective date for the directions, while the &#39;General Controls&#39; section outlines the specific governance and management policies that Regulated Entities - REs - must implement to comply with these directions.| B;
    &lt;/div&gt;

&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;iter 2: changed the prompts a bit to increase no. of nodes and better connections&lt;/summary&gt;
        - new prompts
            - segmentor and summarizer:
&lt;pre&gt;&lt;code&gt;            ```
            Extract as many **short, precise** topics as possible from the given text.
            
                **Rules:**
                - Each topic must be **concise (1-3 words max)**.
                - Aim for **10+ topics** if the content allows.
                - Summarize each topic in **one short sentence**.
                - **Strictly return JSON format only.**
            
                **Example Output:**
                ```json
                {{
                  &amp;quot;topics&amp;quot;: [
                    {{&amp;quot;topic&amp;quot;: &amp;quot;AI in Medicine&amp;quot;, &amp;quot;summary&amp;quot;: &amp;quot;AI enhances diagnostics and treatment&amp;quot;}},
                    {{&amp;quot;topic&amp;quot;: &amp;quot;Fraud Detection&amp;quot;, &amp;quot;summary&amp;quot;: &amp;quot;AI identifies financial fraud in real-time&amp;quot;}},
                    {{&amp;quot;topic&amp;quot;: &amp;quot;Robotics&amp;quot;, &amp;quot;summary&amp;quot;: &amp;quot;Autonomous robots optimize industrial tasks&amp;quot;}},
                    {{&amp;quot;topic&amp;quot;: &amp;quot;Self-Driving Cars&amp;quot;, &amp;quot;summary&amp;quot;: &amp;quot;AI enables autonomous vehicle navigation&amp;quot;}}
                  ]
                }}
                ```
            
                **Text Input:** {text}
            ```
            
        - relationship determiner
            
            ```
            Identify **diverse** relationships between the given topics.
            
                **Rules:**
                - Find as many **relevant connections** as possible.
                - Use **short, precise** relationship descriptions.
                - Relationships should not be **too obvious** (avoid generic links).
                - **Strictly return JSON format only.**
            
                **Example Output:**
                ```json
                {{
                  &amp;quot;relationships&amp;quot;: [
                    {{&amp;quot;from&amp;quot;: &amp;quot;AI in Medicine&amp;quot;, &amp;quot;to&amp;quot;: &amp;quot;Machine Learning&amp;quot;, &amp;quot;relationship&amp;quot;: &amp;quot;Uses ML models&amp;quot;}},
                    {{&amp;quot;from&amp;quot;: &amp;quot;Self-Driving Cars&amp;quot;, &amp;quot;to&amp;quot;: &amp;quot;Computer Vision&amp;quot;, &amp;quot;relationship&amp;quot;: &amp;quot;Relies on CV for object detection&amp;quot;}},
                    {{&amp;quot;from&amp;quot;: &amp;quot;Fraud Detection&amp;quot;, &amp;quot;to&amp;quot;: &amp;quot;AI in Finance&amp;quot;, &amp;quot;relationship&amp;quot;: &amp;quot;Prevents financial crimes&amp;quot;}},
                    {{&amp;quot;from&amp;quot;: &amp;quot;Robotics&amp;quot;, &amp;quot;to&amp;quot;: &amp;quot;AI Ethics&amp;quot;, &amp;quot;relationship&amp;quot;: &amp;quot;Raises ethical concerns&amp;quot;}}
                  ]
                }}
                ```
            
                **Given Topic Data:**  
                ```json
                {segmented_data}
                ```
            
                **Output only JSON. No extra text.**
            ```
            
    - result
        
        &amp;lt;div style=&#39;text-align:center;&#39;&amp;gt;
        &lt;div class=&#34;mermaid&#34;&gt;
            graph TD;
              A[&#34;Digital Payments&#34;];
              B[&#34;Regulatory Framework&#34;];
              C[&#34;Effective Date&#34;];
              D[&#34;Regulated Entities&#34;];
              E[&#34;Definitions&#34;];
              F[&#34;Security Risks&#34;];
              G[&#34;Board Approval&#34;];
              H[&#34;Customer Data&#34;];
              I[&#34;System Availability&#34;];
              J[&#34;Dispute Resolution&#34;];
              K[&#34;Policy Review&#34;];
              L[&#34;User Acceptance Tests&#34;];
              M[&#34;External Assessment&#34;];
              A --&gt;|Subject to various security threats| F;
              A --&gt;|Governed by legal guidelines| B;
              B --&gt;|Defines the scope of entities covered| D;
              C --&gt;|Determines when the legal framework becomes active| B;
              E --&gt;|Provides clarity to the legal terms used| B;
              F --&gt;|Threats can compromise customer information| H;
              F --&gt;|Can lead to service outages| I;
              G --&gt;|Needed for key decisions related to digital payments| A;
              H --&gt;|May be needed to resolve disputes| J;
              I --&gt;|Critical for reliable digital payment services| A;
              K --&gt;|Ensures alignment with evolving legal standards| B;
              L --&gt;|Validates usability before payment platform launch| A;
              M --&gt;|Identifies vulnerabilities and mitigates risks| F;
              G --&gt;|Required for changes to digital payment policies| K;
              M --&gt;|Ensures security of digital payment systems| A;
              D --&gt;|Must adhere to the guidelines for digital payments| A;
            &lt;/div&gt;

        &amp;lt;/div&amp;gt;
        
        &amp;lt;div style=&#39;text-align:center;&#39;&amp;gt;
        &lt;div class=&#34;mermaid&#34;&gt;
            graph TD;
              A[&#34;Graph Theory&#34;];
              B[&#34;TSP&#34;];
              C[&#34;Optimization&#34;];
              D[&#34;Dijkstra&#39;s Algorithm&#34;];
              E[&#34;Held-Karp&#34;];
              F[&#34;Hackathon&#34;];
              G[&#34;Route Optimization&#34;];
              H[&#34;Real-Time Traffic&#34;];
              I[&#34;Google Maps&#34;];
              J[&#34;Streamlit&#34;];
              K[&#34;Web Application&#34;];
              L[&#34;Simplicity&#34;];
              M[&#34;Product Focus&#34;];
              N[&#34;Functionality&#34;];
              A --&gt;|Provides the foundation for representing TSP problems| B;
              B --&gt;|A classic optimization problem| C;
              D --&gt;|Algorithm operating on graphs| A;
              E --&gt;|Dynamic programming approach to solve TSP| B;
              F --&gt;|Context for developing route optimization solutions| G;
              G --&gt;|Can incorporate real-time traffic data for dynamic adjustments| H;
              G --&gt;|Uses maps for calculating efficient routes| I;
              K --&gt;|Built using the Streamlit framework| J;
              F --&gt;|Deliverable of the hackathon| K;
              G --&gt;|May be a practical application or extension of solving TSP| B;
              H --&gt;|Supplement maps data for navigation| I;
              K --&gt;|Focus on core functions over superfluous features| N;
              F --&gt;|Simplicity was a key winning factor| L;
              M --&gt;|Essential for success| F;
              H --&gt;|Adds complexity to route optimization| C;
              B --&gt;|Dijkstra&#39;s algorithm can be used in heuristics to solve TSP| D;
              A --&gt;|Graph theory provides tools used in optimization problems| C;
              G --&gt;|A route optimization feature can be included in the web application| K;
              M --&gt;|Focusing on core functionality is key| N;
              B --&gt;|TSP concepts are used in route optimization| G;
              H --&gt;|Improves route quality in real-time| G;
              N --&gt;|Often related aspects of the same solution| L;
              F --&gt;|Requires product understanding| M;
              K --&gt;|Integrates mapping services| I;
              L --&gt;|Simple design can enhance functionality| N;
              J --&gt;|Tool for building front-end interfaces| K;
              D --&gt;|One possible algorithm for route calculation| G;
              C --&gt;|The goal is to achieve the optimal path| G;
              N --&gt;|Core feature of a product| M;
            &lt;/div&gt;

        &amp;lt;/div&amp;gt;
        
    - thoughts:
        - looks really good
        - however i think the number of connections is too much
        - flow is hard to understand
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;iter 3: tweaked the prompts to give a nice flow and reduce the number of connections&lt;/summary&gt;
&lt;p&gt;changed rel to:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;f&amp;#34;&amp;#34;&amp;#34;
    **Task:** Organize topics into a clear mind map with a structured flow.

    **Rules:**
    - Identify a **main starting topic** (e.g., &amp;#34;AI Applications&amp;#34; or &amp;#34;Machine Learning&amp;#34;).
    - Group related topics under **subcategories** (e.g., &amp;#34;AI in Healthcare&amp;#34; under &amp;#34;AI Applications&amp;#34;).
    - Ensure **a natural progression** from general → specific.
    - Limit connections to **meaningful** ones. Avoid excessive cross-links.
    - **Strictly return JSON format only.**

    **Example Output:**
    ```json
    {{
        &amp;#34;root&amp;#34;: &amp;#34;Artificial Intelligence&amp;#34;,
        &amp;#34;relationships&amp;#34;: [
        {{&amp;#34;from&amp;#34;: &amp;#34;Artificial Intelligence&amp;#34;, &amp;#34;to&amp;#34;: &amp;#34;AI Applications&amp;#34;, &amp;#34;relationship&amp;#34;: &amp;#34;Broad category&amp;#34;}},
        {{&amp;#34;from&amp;#34;: &amp;#34;AI Applications&amp;#34;, &amp;#34;to&amp;#34;: &amp;#34;AI in Healthcare&amp;#34;, &amp;#34;relationship&amp;#34;: &amp;#34;A major domain&amp;#34;}},
        {{&amp;#34;from&amp;#34;: &amp;#34;AI Applications&amp;#34;, &amp;#34;to&amp;#34;: &amp;#34;AI in Finance&amp;#34;, &amp;#34;relationship&amp;#34;: &amp;#34;Used in banking&amp;#34;}},
        {{&amp;#34;from&amp;#34;: &amp;#34;AI in Healthcare&amp;#34;, &amp;#34;to&amp;#34;: &amp;#34;Medical Diagnosis&amp;#34;, &amp;#34;relationship&amp;#34;: &amp;#34;Key use case&amp;#34;}},
        {{&amp;#34;from&amp;#34;: &amp;#34;AI in Finance&amp;#34;, &amp;#34;to&amp;#34;: &amp;#34;Fraud Detection&amp;#34;, &amp;#34;relationship&amp;#34;: &amp;#34;Security application&amp;#34;}}
        ]
    }}
    ```

    **Given Topics:**
    ```json
    {summary}
    ```

    **Output only JSON. No extra text.**
    &amp;#34;&amp;#34;&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;output&lt;/p&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Graph Theory&#34;];
        B[&#34;TSP&#34;];
        C[&#34;Optimization&#34;];
        D[&#34;Algorithms&#34;];
        E[&#34;Hackathon&#34;];
        F[&#34;Route Optimization&#34;];
        G[&#34;Real-time Traffic&#34;];
        H[&#34;APIs&#34;];
        I[&#34;Streamlit&#34;];
        J[&#34;Web Application&#34;];
        K[&#34;Simplicity&#34;];
        L[&#34;Product Focus&#34;];
        M[&#34;Efficacy&#34;];
        F --&gt;|Relies on| C;
        F --&gt;|Implements| D;
        D --&gt;|Utilizes concepts from| A;
        D --&gt;|Solves| B;
        F --&gt;|Data source| H;
        H --&gt;|Provides| G;
        F --&gt;|Interface is| J;
        J --&gt;|Built with| I;
        F --&gt;|Developed during| E;
        F --&gt;|Driven by| L;
        L --&gt;|Emphasizes| K;
        L --&gt;|Aims for| M;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        Graph_Theory[&#34;Graph Theory&#34;];
        TSP[&#34;TSP&#34;];
        Optimization[&#34;Optimization&#34;];
        Dijkstra&#39;s_Algorithm[&#34;Dijkstra&#39;s Algorithm&#34;];
        Held-Karp[&#34;Held-Karp&#34;];
        Hackathon[&#34;Hackathon&#34;];
        Route_Optimization[&#34;Route Optimization&#34;];
        Real-time_Traffic[&#34;Real-time Traffic&#34;];
        Emission_Data[&#34;Emission Data&#34;];
        APIs[&#34;APIs&#34;];
        Streamlit[&#34;Streamlit&#34;];
        Web_Application[&#34;Web Application&#34;];
        Simplicity[&#34;Simplicity&#34;];
        Product_Focus[&#34;Product Focus&#34;];
        Web_Application --&gt;|Frontend framework| Streamlit;
        Route_Optimization --&gt;|Based on| Graph_Theory;
        Route_Optimization --&gt;|Uses mathematical| Optimization;
        Route_Optimization --&gt;|Related to| TSP;
        TSP --&gt;|Algorithm| Dijkstra&#39;s_Algorithm;
        TSP --&gt;|Algorithm| Held-Karp;
        Route_Optimization --&gt;|Considers| Real-time_Traffic;
        Route_Optimization --&gt;|Calculates| Emission_Data;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Graph Theory&#34;];
        B[&#34;TSP&#34;];
        C[&#34;Optimization&#34;];
        D[&#34;Dijkstra&#39;s Algorithm&#34;];
        E[&#34;Held-Karp Algorithm&#34;];
        F[&#34;Hackathon&#34;];
        G[&#34;Route Optimization&#34;];
        H[&#34;Real-time Traffic&#34;];
        I[&#34;APIs&#34;];
        J[&#34;Streamlit&#34;];
        K[&#34;User Experience&#34;];
        L[&#34;Simplicity&#34;];
        M[&#34;Product&#34;];
        N[&#34;Functionality&#34;];
        O[&#34;Steve Jobs&#34;];
        C --&gt;|Encompasses the TSP problem| B;
        A --&gt;|Provides the foundation for| B;
        D --&gt;|Can be a component of| G;
        E --&gt;|Offers a solution approach| B;
        H --&gt;|Influences dynamically| G;
        G --&gt;|Was the challenge at the| F;
        I --&gt;|Delivers real-time data| H;
        I --&gt;|Provides data for| G;
        J --&gt;|Aids in creating intuitive| K;
        K --&gt;|Enhanced by| L;
        M --&gt;|Prioritizes robust| N;
        N --&gt;|Complements clean| L;
        F --&gt;|Offered a lesson in| M;
        O --&gt;|Is an inspiration for| M;
        I --&gt;|Critical component used during| F;
    
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Graph Theory&#34;];
        B[&#34;TSP&#34;];
        C[&#34;Dijkstra&#39;s Algorithm&#34;];
        D[&#34;Held-Karp Algorithm&#34;];
        E[&#34;FedEx Hackathon&#34;];
        F[&#34;Real-time Traffic&#34;];
        G[&#34;Search API&#34;];
        H[&#34;Navigation API&#34;];
        I[&#34;Streamlit&#34;];
        J[&#34;Web Application&#34;];
        K[&#34;Simplicity&#34;];
        L[&#34;Product Understanding&#34;];
        A --&gt;|Provides foundation for| B;
        B --&gt;|Alternative solution approach - limited| C;
        B --&gt;|Solves optimally for smaller instances| D;
        E --&gt;|Inspired a real-world application of| B;
        E --&gt;|Resulted in a| J;
        J --&gt;|Built frontend using| I;
        J --&gt;|Utilized for route guidance| H;
        J --&gt;|Integrated for location finding| G;
        H --&gt;|Considers for optimal routing| F;
        E --&gt;|API provided data| F;
        E --&gt;|Winning strategy emphasized| K;
        E --&gt;|Essential for effective solution| L;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Graph Theory&#34;];
        B[&#34;TSP&#34;];
        C[&#34;Optimization&#34;];
        D[&#34;Dijkstra&#39;s Algorithm&#34;];
        E[&#34;Held-Karp&#34;];
        F[&#34;FedEx Hackathon&#34;];
        G[&#34;Route Optimization&#34;];
        H[&#34;Real-Time Data&#34;];
        I[&#34;API Integration&#34;];
        J[&#34;Streamlit&#34;];
        K[&#34;Web Application&#34;];
        L[&#34;Simplicity&#34;];
        M[&#34;Product Focus&#34;];
        N[&#34;Functionality&#34;];
        B --&gt;|Is a problem within| A;
        C --&gt;|Seeks solutions through| B;
        D --&gt;|Is an algorithm within| A;
        D --&gt;|Can be a component of| G;
        E --&gt;|Solves optimally using dynamic programming| B;
        G --&gt;|Applies principles of| C;
        F --&gt;|Focuses on problems related to| G;
        H --&gt;|Enhances accuracy of| G;
        I --&gt;|Provides sources for| H;
        I --&gt;|Supplies data and services for| G;
        J --&gt;|Facilitates rapid development of| K;
        K --&gt;|The deliverable for| F;
        K --&gt;|Interface for displaying and managing| G;
        L --&gt;|A design principle applied to| K;
        L --&gt;|Prioritized over complexity| N;
        M --&gt;|Drives the user-centered design of| K;
        M --&gt;|Guides the selection of features based on user needs| N;
        N --&gt;|Key element for success in| F;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Digital Payments&#34;];
        B[&#34;Regulation&#34;];
        C[&#34;Applicability&#34;];
        D[&#34;Policy Formulation&#34;];
        E[&#34;Security Risks&#34;];
        F[&#34;Customer Data&#34;];
        G[&#34;Infrastructure&#34;];
        H[&#34;Product Security&#34;];
        I[&#34;Scalability&#34;];
        J[&#34;Dispute Resolution&#34;];
        K[&#34;Review Mechanism&#34;];
        L[&#34;User Acceptance Tests&#34;];
        M[&#34;External Assessment&#34;];
        A --&gt;|Governed by regulatory directions| B;
        B --&gt;|Specifies scope of rules| C;
        A --&gt;|Requires regulated entities to create policies| D;
        D --&gt;|Addresses governance and management of risks| E;
        D --&gt;|Mandates confidentiality protection| F;
        D --&gt;|Ensures availability of infrastructure| G;
        D --&gt;|Focuses on building secure payment products| H;
        D --&gt;|Incorporates capacity building| I;
        D --&gt;|Ensures efficient handling of disputes| J;
        D --&gt;|Includes processes for adequate review| K;
        H --&gt;|Requires UAT before launch| L;
        H --&gt;|Needs external validation| M;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Gitingest&#34;];
        B[&#34;CLI Tool&#34;];
        C[&#34;Python Package&#34;];
        D[&#34;Browser Extension&#34;];
        E[&#34;Self-Hosting&#34;];
        F[&#34;Contributing&#34;];
        G[&#34;Code of Conduct&#34;];
        H[&#34;Security Policy&#34;];
        I[&#34;pyproject.toml&#34;];
        J[&#34;requirements.txt&#34;];
        K[&#34;pre-commit&#34;];
        L[&#34;Filesystem schema&#34;];
        M[&#34;Query parsing&#34;];
        N[&#34;Output formatting&#34;];
        O[&#34;Server API&#34;];
        P[&#34;GitHub Actions&#34;];
        A --&gt;|Exposes functionality through| B;
        A --&gt;|Provides as an importable| C;
        A --&gt;|Offers for code analysis in browsers| D;
        A --&gt;|Supports via Docker| E;
        A --&gt;|Welcomes contributions to| F;
        A --&gt;|Governed by| G;
        A --&gt;|Maintains a| H;
        A --&gt;|Automates CI/CD with| P;
        B --&gt;|Uses for processing input sources| M;
        B --&gt;|Utilizes for presenting results| N;
        C --&gt;|Uses for processing input sources| M;
        C --&gt;|Utilizes for presenting results| N;
        E --&gt;|Accesses through a| O;
        F --&gt;|Adheres to| G;
        F --&gt;|Uses for testing contributions| P;
        A --&gt;|Uses to manage project metadata| I;
        A --&gt;|Defines Python dependencies in| J;
        A --&gt;|Enforces code quality with| K;
        A --&gt;|Operates based on a defined| L;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Gitingest Tool&#34;];
        B[&#34;Code of Conduct&#34;];
        C[&#34;Contributing&#34;];
        D[&#34;Dockerfile&#34;];
        E[&#34;MIT License&#34;];
        F[&#34;Security Policy&#34;];
        G[&#34;CLI Interface&#34;];
        H[&#34;Repository Cloning&#34;];
        I[&#34;Configuration&#34;];
        J[&#34;Exception Handling&#34;];
        K[&#34;File System Schema&#34;];
        L[&#34;Ingestion Process&#34;];
        M[&#34;Output Formatting&#34;];
        N[&#34;Query Parsing&#34;];
        O[&#34;Server Main&#34;];
        P[&#34;FastAPI Server&#34;];
        Q[&#34;Query Processing&#34;];
        R[&#34;Server Utilities&#34;];
        S[&#34;Web Application&#34;];
        T[&#34;Github Actions&#34;];
        A --&gt;|Offers command-line access| G;
        A --&gt;|Provides API endpoints| P;
        A --&gt;|Core analysis functionality| L;
        A --&gt;|Usage is governed by| E;
        A --&gt;|Project adheres to| B;
        A --&gt;|Follows guidelines for contributions| C;
        A --&gt;|Provides details for reporting vulnerabilities| F;
        G --&gt;|Uses for input validation| N;
        G --&gt;|Reads settings from| I;
        P --&gt;|Entry point for| O;
        P --&gt;|Manages backend requests| Q;
        P --&gt;|Utilizes helper methods| R;
        P --&gt;|Serves frontend components| S;
        L --&gt;|Requires access to codebases| H;
        L --&gt;|Represents file structures| K;
        L --&gt;|Generates analysis results| M;
        L --&gt;|Reports processing errors| J;
        A --&gt;|Containerized using| D;
        A --&gt;|Uses for CI/CD| T;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;FedEx Route Planner&#34;];
        B[&#34;Streamlit App&#34;];
        C[&#34;TomTom API&#34;];
        D[&#34;HERE API&#34;];
        E[&#34;Traffic Data&#34;];
        F[&#34;Emission Factors&#34;];
        G[&#34;Travel Mode&#34;];
        H[&#34;Input Mode&#34;];
        I[&#34;Optimal Route&#34;];
        J[&#34;TSP Solving&#34;];
        K[&#34;Route Visualization&#34;];
        L[&#34;Emission Calculation&#34;];
        A --&gt;|Implemented as| B;
        A --&gt;|Aims to find| I;
        A --&gt;|Integrates| L;
        I --&gt;|Achieved through| J;
        I --&gt;|Uses for route generation| C;
        I --&gt;|Considers for route adjustments| E;
        L --&gt;|Uses for estimation| F;
        L --&gt;|Depends on| G;
        B --&gt;|Offers configuration via| H;
        B --&gt;|Provides user interface for| K;
        H --&gt;|Uses for location to coordinate conversion| D;
        K --&gt;|Employs for map display| C;
        C --&gt;|Provides real-time| E;
    &lt;/div&gt;

  &lt;/div&gt;
  &lt;div style=&#39;text-align:center;&#39;&gt;
  &lt;div class=&#34;mermaid&#34;&gt;
    graph TD;
        A[&#34;Public-Private Partnership&#34;];
        B[&#34;Sports Sector&#34;];
        C[&#34;Odisha State&#34;];
        D[&#34;Economic Growth&#34;];
        E[&#34;Policy Implementation&#34;];
        F[&#34;Sports Development&#34;];
        G[&#34;Tokyo Olympics&#34;];
        H[&#34;Literature Review&#34;];
        I[&#34;Research Method&#34;];
        J[&#34;Global Perspectives&#34;];
        K[&#34;Indian Context&#34;];
        L[&#34;Infrastructure&#34;];
        M[&#34;Transportation&#34;];
        N[&#34;Healthcare&#34;];
        O[&#34;Education &amp; Technology&#34;];
        P[&#34;Odisha Model&#34;];
        Q[&#34;High-Performance Centers&#34;];
        R[&#34;Managerial Implications&#34;];
        S[&#34;Legal Clearances&#34;];
        T[&#34;Private Capital&#34;];
        U[&#34;Goal Alignment&#34;];
        A --&gt;|Increasingly used for infrastructure and development| B;
        A --&gt;|Contributes to sectoral growth and athlete performance| D;
        A --&gt;|Managerial implications for successful implementation| E;
        A --&gt;|Informed by existing research across sectors| H;
        A --&gt;|Models exist in Europe, North America, and South America| J;
        A --&gt;|Used in infrastructure, transportation, tourism, education, and healthcare| K;
        B --&gt;|Crucial for achieving national sporting ambitions| F;
        B --&gt;|Serves as a role model for PPP implementation| C;
        B --&gt;|India&#39;s success demonstrates the need for PPP in sports| G;
        E --&gt;|Emphasizes legal clearances, capital access, goal alignment, and project management| R;
        R --&gt;|Requires a robust framework for private organizations to plan risks| S;
        R --&gt;|Benefits from transparency to increase investment confidence| T;
        R --&gt;|Relies on understanding roles for project success| U;
        K --&gt;|PPP faces challenges like regulatory issues and capital raising| L;
        K --&gt;|PPP projects experience less time overrun| M;
        K --&gt;|PPP improves delivery in backward districts| N;
        K --&gt;|PPP reduces financial pressure on government-run schools| O;
        C --&gt;|Sports policy aims to develop all socio-economic groups| P;
        C --&gt;|Established HPCs in various sporting disciplines| Q;
        I --&gt;|Utilizes academic databases and government documents to gather existing research| H;
    &lt;/div&gt;

  &lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/details&gt;
&lt;p&gt;thoughts: i think these final prompts are good.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;combined thing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;iter1:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;made a streamlit front end&lt;/li&gt;
&lt;li&gt;takes in pdfs&lt;/li&gt;
&lt;li&gt;checks whether an image based pdf or text based&lt;/li&gt;
&lt;li&gt;uses easyocr and pypdf2 for image and text based pdfs respectively&lt;/li&gt;
&lt;li&gt;extracted text given to segmentor and summarizer&lt;/li&gt;
&lt;li&gt;gives topics and summaries, displayed there&lt;/li&gt;
&lt;li&gt;passed to relationship generator. generates relationships within each thing. prints them&lt;/li&gt;
&lt;li&gt;one combined relationship generator. topic wise summaries given together, gives the relationships and prints the mermaid diagram&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;// problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;shows syntax error many times&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;// now need to change it to give the content to relationship generator&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iter2: content goes to the relationship generator. the topics are decided on the basis of major topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iter3: segments on the basis of titles, gives content to both rel and summarizer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;change summarize prompt&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iter4: segments on its own, gives content to both rel and summarizer&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;there are 4 options available&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;segment and summarize together, ie the model decides the main topics. send topic wise summaries to relationship maker&lt;/li&gt;
&lt;li&gt;segment on the basis of titles, and then summarize, ie the topics are decided on the basis of how they’re presented in the doc then send topic wise summaries&lt;/li&gt;
&lt;li&gt;segment on the basis of titles, send content to summarizer to display summaries. relationship maker also gets content.&lt;/li&gt;
&lt;li&gt;segment according to what it thinks the major topics are, then send content to summarizer and relationship maker.
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;content to rel&lt;/th&gt;
          &lt;th&gt;no content to rel&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;titles&lt;/td&gt;
          &lt;td&gt;iter3&lt;/td&gt;
          &lt;td&gt;iter2&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;own&lt;/td&gt;
          &lt;td&gt;iter4&lt;/td&gt;
          &lt;td&gt;iter1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;benefits of extracting titles on its own are that big files get segregated into small topics that are easy to understand.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;failed to generate topics error cuz “s, \escape in json, expecting delimiter etc
&lt;ul&gt;
&lt;li&gt;either remove these problem creating elements or donot extract content.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;because of the reason listed above, we get rid of iter3, 4.&lt;/p&gt;
&lt;p&gt;now in iter2, 1, i think it is more relevant if we do it file wise for github repos and otherwise for other pdfs.&lt;/p&gt;
&lt;p&gt;iter 1 final&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;added the functionality to take in github repos&lt;/li&gt;
&lt;li&gt;changed the prompts to be different for pdfs and repos&lt;/li&gt;
&lt;li&gt;need to make the following fixes:
&lt;ul&gt;
&lt;li&gt;syntax error&lt;/li&gt;
&lt;li&gt;mindmaps not viewable nicely&lt;/li&gt;
&lt;li&gt;ui/ux changes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;[17/3/25]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;integrated mistral’s ocr&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;omg it looks so good, i changed text based pdfs to also go through mistrals ocr&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cleaned the code, divided into various files and enabled the functions to be imported from there&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;need to make ui changes&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;need to create .env&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;run the prompts through chatgpt and get better ones&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;need to structure json&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;need to integrate caching&lt;/del&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;[18/3/25]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the mermaid diagrams arent being represented nicely, they’re usually being cut off at the bottom unless i make the container size atypically large, which makes it very out of place.
&lt;ul&gt;
&lt;li&gt;tried numerous work arounds, nothing seemed to work&lt;/li&gt;
&lt;li&gt;then randomly came across a python library that helps to display mermaid code in streamlit and it worked like a charm&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;trying to get better prompts
&lt;ul&gt;
&lt;li&gt;explained the pipeline to chatgpt, gave current prompts and asked it to generate newer and more precise ones&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;del&gt;need to improve the colour scheme&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;made prompt changes, ui changes, looks really cool. just need to integrate rag now.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/AIAnytime/Project-WebSage&#34;&gt;Project-WebSage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;^ rag based llm integration for website search&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;[26/3/25]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;deployed on streamlit&lt;/li&gt;
&lt;li&gt;looks so fking good; i can access it through my phone, any of my browsers, literally anywhere and the best part is taht it comes with batteries included- no need to put any api keys &amp;lt;333&lt;/li&gt;
&lt;li&gt;fixes
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;api keys should be locally sourced&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;the embeddings stay the same despite a new repo been given&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;the embeddings remain same across different devices - the same repo was being referred to on my phone for llm chat despite a different pdf that i had entered initially.&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;changed such that new embeddings are generated each time a file is given&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;del&gt;still shows the CachedWidgetWarning&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;put the widget generate outside the cached function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;syntax error&lt;/li&gt;
&lt;li&gt;&lt;del&gt;not loading ask ai for pdfs&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;fixed it by resetting variables whenever the input mode is changed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;update readme&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;[27/3/25]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;del&gt;minor fixes&lt;/del&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; change size of chat dialog&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; change k factor&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; change prompt to ignore useless files&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;final-pipeline&#34;&gt;final pipeline:&lt;/h4&gt;
&lt;div style=&#39;text-align:center;&#39;&gt;
&lt;div class=&#34;mermaid&#34;&gt;
flowchart TD;
A[user input]--&gt;|&#34;github repo&#34;|B[github_scraper.py]
A --&gt; |&#34;pdf document&#34;|C[pdf_ocr.py]
B--&gt;|&#34;content&#34;|H
C--&gt;|&#34;content&#34;|H
H[&#34;content json&#34;]--&gt;D[segmentor_summarizer.py]
H--&gt;|embeddings|I[vector store]
I--&gt;|&#34;context&#34;|J[&#34;ask ai rag&#34;]
D--&gt;|&#34;major topics and summaries&#34;|E[relationship_generator.py]
E--&gt;|&#34;relationships json&#34;|F[generator.py]
F--&gt;|mermaid code|G[streamlit frontend]
&lt;/div&gt;

&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;finally. its all done. finally. got it ready. up and running, up and running beautifully. on the web. anybody from any corner of the world can use it anywhere at any corner of the world. no need for api keys, no need for downloads. just one click and you enter your mindpalace.&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;launched it on linkedin. put it on a bunch of subreddits and also on hacker news. got a bunch of positive reviews, including those from my close friends. (added more on my learnings from mindpalace in the 9/4/25 blog &lt;a href=&#34;https://1rvinn.github.io/crude/090425&#34;&gt;here.&lt;/a&gt;)&lt;/p&gt;
&lt;iframe src=&#34;https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:7311414641471983616?collapsed=1&#34; height=&#34;551&#34; width=&#34;504&#34; frameborder=&#34;0&#34; allowfullscreen=&#34;&#34; title=&#34;Embedded post&#34;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;strong&gt;update [8/4/25]:&lt;/strong&gt; &lt;br&gt;
&lt;br&gt;
on a friend&amp;rsquo;s feedback, i added the functionality of saving the mindmaps as images. used the &lt;a href=&#34;https://kroki.io/&#34;&gt;kroki&lt;/a&gt; api endpoint to convert mermaid code into pngs and made them available for download.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>let yourself die</title>
      <link>https://1rvinn.github.io/crude/let-yourself-die/</link>
      <pubDate>Sat, 15 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/let-yourself-die/</guid>
      <description>&lt;p&gt;let yourself die.&lt;/p&gt;
&lt;p&gt;for when you live you have to ply&lt;/p&gt;
&lt;p&gt;by societal constructs, and cry&lt;/p&gt;
&lt;p&gt;the confirmist wry.&lt;/p&gt;
&lt;p&gt;let the sense of self die,&lt;/p&gt;
&lt;p&gt;and no longer you’re a node in the society;&lt;/p&gt;
&lt;p&gt;the chains are all set free;&lt;/p&gt;
&lt;p&gt;eternal freedom is bestowed,&lt;/p&gt;
&lt;p&gt;and you can fly to where you want to be.&lt;/p&gt;
&lt;p&gt;attain freedom hereby,&lt;/p&gt;
&lt;p&gt;let yourself die.&lt;/p&gt;</description>
      <content>&lt;p&gt;let yourself die.&lt;/p&gt;
&lt;p&gt;for when you live you have to ply&lt;/p&gt;
&lt;p&gt;by societal constructs, and cry&lt;/p&gt;
&lt;p&gt;the confirmist wry.&lt;/p&gt;
&lt;p&gt;let the sense of self die,&lt;/p&gt;
&lt;p&gt;and no longer you’re a node in the society;&lt;/p&gt;
&lt;p&gt;the chains are all set free;&lt;/p&gt;
&lt;p&gt;eternal freedom is bestowed,&lt;/p&gt;
&lt;p&gt;and you can fly to where you want to be.&lt;/p&gt;
&lt;p&gt;attain freedom hereby,&lt;/p&gt;
&lt;p&gt;let yourself die.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>privacy, democratization in ai</title>
      <link>https://1rvinn.github.io/crude/fed/</link>
      <pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/fed/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;recently, while reading about the recent developments in the field i realised an array of issues that, in my opinion, are being overlooked in the current paradigm:&lt;/p&gt;&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;monopolisation&lt;/strong&gt; &lt;br&gt;
Due to the humongous data requirement for pre-training, we see big-data companies like the &amp;lsquo;Googles&amp;rsquo; and &amp;lsquo;Microsofts&amp;rsquo; of the world having an unfair competitive edge over other smaller corporations or entities in developing such models. This not only means a handful of companies have control over such a quintessential field but also implies:
&lt;br&gt;
[D] soft power - greater soft power over all AI-based content, which could further transcend into propagating bias through content and controlling widespread opinions about sensitive topics across the entire world.
&lt;br&gt;
[P] access to user data - with the advent of time, as AI becomes an indispensable part of our lives, these handful corporations will have even greater access to user data across different use cases, making them even more powerful. Not only this but these days, the most popular LLMs use consumer data for further training, while only mentioning this very subtly in their privacy policy. This makes room for a plethora of data security leaks on the cloud where this data is hosted and other data attacks such as prompt injection.
&lt;br&gt;
[D] by virtue of huge data and state-of-the-art compute requirements, it is only the firms with a rich history in tech and high levels of disposable income to spend, who can establish themselves in this area, making it discriminatorily hard for smaller firms to emerge in this field. This also means a geopolitical issue for 2nd and 3rd world countries being completely dependent upon the 1st world for such foundational models.&lt;/p&gt;</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;recently, while reading about the recent developments in the field i realised an array of issues that, in my opinion, are being overlooked in the current paradigm:&lt;/p&gt;&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;monopolisation&lt;/strong&gt; &lt;br&gt;
Due to the humongous data requirement for pre-training, we see big-data companies like the &amp;lsquo;Googles&amp;rsquo; and &amp;lsquo;Microsofts&amp;rsquo; of the world having an unfair competitive edge over other smaller corporations or entities in developing such models. This not only means a handful of companies have control over such a quintessential field but also implies:
&lt;br&gt;
[D] soft power - greater soft power over all AI-based content, which could further transcend into propagating bias through content and controlling widespread opinions about sensitive topics across the entire world.
&lt;br&gt;
[P] access to user data - with the advent of time, as AI becomes an indispensable part of our lives, these handful corporations will have even greater access to user data across different use cases, making them even more powerful. Not only this but these days, the most popular LLMs use consumer data for further training, while only mentioning this very subtly in their privacy policy. This makes room for a plethora of data security leaks on the cloud where this data is hosted and other data attacks such as prompt injection.
&lt;br&gt;
[D] by virtue of huge data and state-of-the-art compute requirements, it is only the firms with a rich history in tech and high levels of disposable income to spend, who can establish themselves in this area, making it discriminatorily hard for smaller firms to emerge in this field. This also means a geopolitical issue for 2nd and 3rd world countries being completely dependent upon the 1st world for such foundational models.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;climate impact&lt;/strong&gt; &lt;br&gt;
[D] these foundational models require huge loads of compute requirements for pre-training. This means great amounts of energy requirements, so much so that companies like Microsoft have rented complete nuclear reactors to satisfy the energy hunger of their AI programmes. This move is completely counterintuitive to the sustainability efforts being done to reverse climate change.
&lt;br&gt;
[S] this tradeoff, considering the first set of harms [1] as well, is completely unjustified and will only lead humanity to its doom.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;low Levels of Development in the essential fields of Healthcare and Finance&lt;/strong&gt; &lt;br&gt;
[P] since these models require unrestricted access to data to be trained, coupled with the issue that healthcare and financial data being highly private, we haven&amp;rsquo;t seen any major breakthroughs in these areas. AI has immense potential to change the lives of millions provided there is enough sustainable development in these fields, but the only thing that is holding us back is access to highly private data which is a justified concern given the first set of issues [1].&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;with all these concerns in mind, I came across this interesting framework called Federated Learning. coupled with a very interesting encryption scheme - homomorphic encryption - it can solve all the above-listed problems.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;federated learning:&lt;/strong&gt; &lt;br&gt;
In the current paradigm, the data travels to the model, and the model is trained. But what if the model travels to the data for training? That is, there is no transfer of data, therefore no room for data leaks, privacy issues and greater accessibility for smaller companies without data to compete with big giants.
&lt;br&gt;
This also needs better innovation as the race now changes to creating novel architectures rather than winning with more data.
&lt;br&gt;
Additionally, now there is a greater variety of data available to train these models including personal data - healthcare, financial data. This means better foundation models and more innovation in these underdeveloped areas.
&lt;br&gt;
Also, it means that the model is trained on individual devices, which implies that the computational and energy requirements are divided across devices, thus offloading the burden on the central server.
&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://1rvinn.github.io/img/crude/fed/fed1.png&#34; alt=&#34;federated learning&#34;&gt;
&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;homomorphic encryption:&lt;/strong&gt;
&lt;br&gt;
in the current paradigm, this is how data encryption looks like during LLM inference:
&lt;br&gt;
&lt;br&gt;
&lt;img src=&#34;https://1rvinn.github.io/img/crude/fed/fed2.png&#34; alt=&#34;homomorphic encryption&#34;&gt;
&lt;br&gt;
the inference is done on decrypted data, which leads to a loophole that can be exploited by cyber attackers. Not only this, but it can also lead to other security issues like the LLM learning about personal details and prompt injections as elaborated in [1].
&lt;br&gt;
homomorphic encryption prevents this by supporting calculations to be made on encrypted data itself, mitigating any data security threats.
&lt;br&gt;
additionally, being based upon lattice-based cryptography, it is resilient to the rise of quantum computers which pose a threat to existing encryption schemes like the RSA.
&lt;br&gt;
\&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;if you notice, I have segregated the above problems into three categories - [D]: Democratization of AI, [P]: Privacy, [S]: Sustainability.
&lt;br&gt;
&lt;br&gt;
these 3 issues are often always overlooked whenever there is a big innovation, but later, people realise the importance of working on these - the same happened in the case of Internet, with heavy spending on cybersecurity, sustainability and privacy being prevalent only these days.
&lt;br&gt;
&lt;br&gt;
the above two frameworks can solve all these issues, empowering even a small startup from Maharashtra in India to compete with OpenAI based out of San Francisco. I truly believe this could be a revolutionary step for democratising AI development and boosting security.&lt;/p&gt;&lt;/blockquote&gt;
</content>
    </item>
    
    <item>
      <title>jobs: the man who could change reality</title>
      <link>https://1rvinn.github.io/crude/jobs/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/jobs/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;“Steve was a wizard, he would be casting spells, and I’d be seeing people get mesmerized” &lt;br&gt;&lt;br&gt; ~ Bill Gates on Steven Paul Jobs&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Calling Steve Jobs an ‘innovator’, a ‘great marketing mind’, or a ‘sharp entrepreneur’ would be an understatement. Because his abilities were nothing short of superpowers — Jobs could change reality.&lt;/p&gt;
&lt;p&gt;Reading Isaacson’s biography of Jobs and taking a deep dive into the infinite ocean of movies, shows, and articles about Apple exposed me to the genius of Mac’s godfather. One characteristic that stuck out to me was Steve’s Reality Distortion Field. Coining the term, Bud Tribble — an early employee at Apple, described Steve’s ability to bend the realities of those around him. The ability to convince others to believe almost anything, thanks to his charm, charisma, and marketing acumen. It was said he could distort his co-workers’ sense of difficulty and make them believe that whatever impossible task they had at hand was possible.
‘In his presence, reality is malleable. He can convince anyone of practically anything.’&lt;/p&gt;</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;“Steve was a wizard, he would be casting spells, and I’d be seeing people get mesmerized” &lt;br&gt;&lt;br&gt; ~ Bill Gates on Steven Paul Jobs&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Calling Steve Jobs an ‘innovator’, a ‘great marketing mind’, or a ‘sharp entrepreneur’ would be an understatement. Because his abilities were nothing short of superpowers — Jobs could change reality.&lt;/p&gt;
&lt;p&gt;Reading Isaacson’s biography of Jobs and taking a deep dive into the infinite ocean of movies, shows, and articles about Apple exposed me to the genius of Mac’s godfather. One characteristic that stuck out to me was Steve’s Reality Distortion Field. Coining the term, Bud Tribble — an early employee at Apple, described Steve’s ability to bend the realities of those around him. The ability to convince others to believe almost anything, thanks to his charm, charisma, and marketing acumen. It was said he could distort his co-workers’ sense of difficulty and make them believe that whatever impossible task they had at hand was possible.
‘In his presence, reality is malleable. He can convince anyone of practically anything.’&lt;/p&gt;
&lt;p&gt;Jobs undoubtedly was a great visionary, envisioning products way ahead of time — be it the Mac, iPod or iPhone. Yet, his greatest skill lay in convincing people that his vision was not just a predictive idea but a true reflection of the future. His enchanting keynote sessions, also referred to as Stevenotes, are a testament to this. Be it convincing millions to pay $900 extra for the first Mac because ‘app windows must have rounded corners’ or convincing that headphone jacks are unnecessary, he could bend others’ realities to align with his vision. Now, this is aura!&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>the metamorphosis</title>
      <link>https://1rvinn.github.io/crude/the-metamorphosis/</link>
      <pubDate>Tue, 04 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://1rvinn.github.io/crude/the-metamorphosis/</guid>
      <description>&lt;p&gt;The Metamorphosis by Franz Kafka is a beautiful short story depicting the intricacies of human psyche and relationships. The story starts off with Gregor, the family&amp;rsquo;s sole breadwinner, waking up to find himself metamorphosed into a mammoth of an insect. Following that, Kafka describes the paradigm shift in the demeanour of those around him — his boss, his family, and even Gregor himself.&lt;/p&gt;
&lt;p&gt;Despite this pathetic condition of his, Gregor never thinks of himself. Instead, his mind is flooded with the fear of getting late for the train he has to catch, failing which he’d surely get a reprimand from his boss. This portrays how blinded humankind nowadays is, running a rat race, trying to satisfy the unsatisfiable — their never-ending greed.&lt;/p&gt;</description>
      <content>&lt;p&gt;The Metamorphosis by Franz Kafka is a beautiful short story depicting the intricacies of human psyche and relationships. The story starts off with Gregor, the family&amp;rsquo;s sole breadwinner, waking up to find himself metamorphosed into a mammoth of an insect. Following that, Kafka describes the paradigm shift in the demeanour of those around him — his boss, his family, and even Gregor himself.&lt;/p&gt;
&lt;p&gt;Despite this pathetic condition of his, Gregor never thinks of himself. Instead, his mind is flooded with the fear of getting late for the train he has to catch, failing which he’d surely get a reprimand from his boss. This portrays how blinded humankind nowadays is, running a rat race, trying to satisfy the unsatisfiable — their never-ending greed.&lt;/p&gt;
&lt;p&gt;Upon realising Gregor’s handicap, the family understood that they must give up on the somewhat comfortable lives they were leading and get back to work in order to sustain themselves. His father picked up the job of a security guard; his mother took up tiny gags, and even his sister, Grete, although only seventeen, decided to go door to door working as a saleswoman.&lt;/p&gt;
&lt;p&gt;And Gregor? Oh, he was not to be disturbed in his room. Owing to his pathetic condition, neither of his parents had the courage even to bear the sight of their metamorphosed son. In these circumstances, his sister took the responsibility of feeding her brother and cleaning his room. This continued for a while, but the initial warm love and compassion for her brother was eventually seen fading away. Specific incidents further catalysed this dwindling of emotions to the point that, leave alone his parents, even his sister, started perceiving Gregor as a burden. This further led to her pleading with her parents to get rid of it. And I’m right when I used ‘it’. She no longer believed that the insect could actually be her beloved brother, Gregor.&lt;/p&gt;
&lt;p&gt;Owing to the above incidents, I believe that ‘The Metamorphosis’ isn’t just a story about Gregor’s metamorphosis but also that of his sister. Kafka has just portrayed what is often seen in families these days: an elderly member falling terminally ill is taken good care of, but only to a point. Despite what they have done for their families, the latter eventually start perceiving these people as burdens — financial and mental — and end up leaving them to their own disposal. Another relevant example could be how, after the passing away of a family member, they’re kept alive in the heads of their loved ones by memories but, with the due advent of time, even those memories fade away and along fades the emotional connection one had.&lt;/p&gt;
&lt;p&gt;Kafka’s works are known for bitterly painful endings, and this one was no different. One night, just after observing his sister’s metamorphosis, frail due to the injuries and infections he had picked up, malnourished due to the sheer lack of food, and mentally broken due to the torments he had been through, Gregor exhaled his final breaths.&lt;/p&gt;
&lt;p&gt;Along with Gregor went the various aspirations he held — sending his sister to music school, no matter the expenses, settling in a good apartment with his parents. Here’s Kafka providing us with another lesson for life — certain incidents might completely derail your healthy, happy and tranquil life, leaving you no choice but to accept fate and let go of what held utmost importance to you, of what you held closest to your heart. Therefore, wait not for the right time to act, for the right time is right now.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
